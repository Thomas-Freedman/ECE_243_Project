{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_decoder.dataset import SpeechDataset\n",
    "from neural_decoder.advanced_trainer import train_advanced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bcd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.expanduser(\"~/competitionData/ptDecoder_ctc\")\n",
    "OUTPUT_DIR = os.path.expanduser(\"~/results/advanced_simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47075a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'variant': 'advanced',\n",
    "    'batchSize': 16,\n",
    "    'nBatch': 30000,\n",
    "    'seed': 0,\n",
    "    'lr': 0.005,\n",
    "    'weightDecay': 0.0001,\n",
    "    'nClasses': 40,\n",
    "    'nInputFeatures': 256,\n",
    "    'strideLen': 4,\n",
    "    'kernelLen': 8,\n",
    "    'gaussianSmoothWidth': 2.0,\n",
    "    'modelDim': 512,\n",
    "    'modelLayers': 6,\n",
    "    'modelHeads': 8,\n",
    "    'dropout': 0.2,\n",
    "    'intermediateLayer': 3,\n",
    "    'timeMaskRatio': 0.6,\n",
    "    'channelDropProb': 0.3,\n",
    "    'featureMaskProb': 0.1,\n",
    "    'minTimeMask': 16,\n",
    "    'consistencyWeight': 0.2,\n",
    "    'intermediateLossWeight': 0.3,\n",
    "    'testTimeLR': 0.0001,\n",
    "    'enableTestTimeAdaptation': True,\n",
    "    'enableOnlineAdaptation': True,\n",
    "    'onlineAdaptationLR': 0.00001,\n",
    "    'diphoneContext': 40,\n",
    "    'transformerTimeMaskProb': 0.1,\n",
    "    'relPosMaxDist': None,\n",
    "    'relBiasByHead': True,\n",
    "    'ffMult': 4,\n",
    "    'outputDir': OUTPUT_DIR,\n",
    "    'datasetPath': DATASET_PATH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ADVANCED TRANSFORMER MODEL TRAINING\")\n",
    "print(\"WARNING: This model typically gets ~72% CER (worse than baseline)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nStarting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_advanced_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uygbeq4tlv",
   "metadata": {},
   "source": [
    "# Language Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lfor9kpgp69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KenLM if not already installed\n",
    "try:\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing KenLM...\")\n",
    "    ! pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM installed successfully\")\n",
    "\n",
    "from neural_decoder.phoneme_lm import PhonemeLM, beam_search_decode, create_phoneme_map\n",
    "from neural_decoder.advanced_models import StreamingTransformerDecoder\n",
    "from edit_distance import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "LM_PATH = \"phoneme_lm.arpa\"\n",
    "phoneme_map = create_phoneme_map()\n",
    "lm = PhonemeLM(LM_PATH, phoneme_map=phoneme_map)\n",
    "print(f\"✓ Language Model loaded from: {LM_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sdjoc8nvg4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open(DATASET_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "test_ds = SpeechDataset(data[\"test\"])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X, y, X_lens, y_lens, days = zip(*batch)\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0.0)\n",
    "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    return (\n",
    "        X_padded,\n",
    "        y_padded,\n",
    "        torch.stack(X_lens),\n",
    "        torch.stack(y_lens),\n",
    "        torch.stack(days),\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=args['batchSize'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "model = StreamingTransformerDecoder(\n",
    "    neural_dim=args['nInputFeatures'],\n",
    "    n_phonemes=args['nClasses'],\n",
    "    d_model=args['modelDim'],\n",
    "    nhead=args['modelHeads'],\n",
    "    num_layers=args['modelLayers'],\n",
    "    nDays=len(data[\"train\"]),\n",
    "    dropout=args['dropout'],\n",
    "    device=device,\n",
    "    strideLen=args['strideLen'],\n",
    "    kernelLen=args['kernelLen'],\n",
    "    gaussianSmoothWidth=args['gaussianSmoothWidth'],\n",
    "    ff_mult=args['ffMult'],\n",
    "    rel_pos_max_dist=args['relPosMaxDist'],\n",
    "    diphone_context=args['diphoneContext'],\n",
    ").to(device)\n",
    "\n",
    "weights_path = os.path.join(OUTPUT_DIR, \"modelWeights.pt\")\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded from: {weights_path}\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kae0hmsovfn",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_baseline = []\n",
    "all_predictions_lm = []\n",
    "all_targets = []\n",
    "\n",
    "LM_WEIGHT = 0.8  \n",
    "BEAM_WIDTH = 10 \n",
    "\n",
    "print(f\"LM Weight: {LM_WEIGHT}\")\n",
    "print(f\"Beam Width: {BEAM_WIDTH}\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X, y, X_len, y_len, day_idx) in enumerate(test_loader):\n",
    "        X = X.to(device)\n",
    "        X_len = X_len.to(device)\n",
    "        day_idx = day_idx.to(device)\n",
    "        \n",
    "\n",
    "        output = model(X, X_len, day_idx)\n",
    "        logits = output['log_probs'].exp()  \n",
    "        lengths = output['eff_lengths']\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            seq_len = int(lengths[i])\n",
    "            lp = log_probs[i, :seq_len, :]\n",
    "            \n",
    "            greedy = torch.argmax(lp, dim=-1).cpu().numpy()\n",
    "            decoded_baseline = []\n",
    "            prev = None\n",
    "            for tok in greedy:\n",
    "                if tok == prev or tok == 0:\n",
    "                    prev = tok\n",
    "                    continue\n",
    "                decoded_baseline.append(tok)\n",
    "                prev = tok\n",
    "            all_predictions_baseline.append(decoded_baseline)\n",
    "            \n",
    "            decoded_lm = beam_search_decode(\n",
    "                lp,\n",
    "                lm=lm,\n",
    "                lm_weight=LM_WEIGHT,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                blank_id=0,\n",
    "                topk_acoustic=5\n",
    "            )\n",
    "            all_predictions_lm.append(decoded_lm)\n",
    "            \n",
    "            target = y[i, :y_len[i]].cpu().numpy().tolist()\n",
    "            all_targets.append(target)\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "\n",
    "print(\"✓ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lw89jkly65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(predictions, targets):\n",
    "    total_edit = 0\n",
    "    total_len = 0\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        matcher = SequenceMatcher(a=target, b=pred)\n",
    "        total_edit += matcher.distance()\n",
    "        total_len += len(target)\n",
    "    return total_edit / total_len if total_len > 0 else 0.0\n",
    "\n",
    "cer_baseline = compute_error_rate(all_predictions_baseline, all_targets)\n",
    "cer_lm = compute_error_rate(all_predictions_lm, all_targets)\n",
    "improvement = (cer_baseline - cer_lm) / cer_baseline * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBaseline (Greedy):\")\n",
    "print(f\"  CER: {cer_baseline:.4f} ({cer_baseline*100:.2f}%)\")\n",
    "print(f\"\\nWith Language Model:\")\n",
    "print(f\"  CER: {cer_lm:.4f} ({cer_lm*100:.2f}%)\")\n",
    "print(f\"  Improvement: {improvement:.2f}% relative\")\n",
    "print(f\"  Absolute gain: {(cer_baseline - cer_lm)*100:.2f} percentage points\")\n",
    "print(f\"Language Model improved accuracy by {improvement:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
