{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple final model training script - reads from config file\n",
    "Optimized GRU with SGD\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "from edit_distance import SequenceMatcher\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257991e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_decoder.dataset import SpeechDataset\n",
    "from neural_decoder.model import GRUDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD CONFIGURATION\n",
    "# ============================================================================\n",
    "CONFIG_PATH = \"src/neural_decoder/conf/decoder/final.yaml\"\n",
    "DATASET_PATH = os.path.expanduser(\"~/competitionData/ptDecoder_ctc\")\n",
    "OUTPUT_DIR = os.path.expanduser(\"~/results/final_simple\")\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL MODEL TRAINING (Optimized GRU + SGD)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f98eb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f\"\\nLoaded configuration from: {CONFIG_PATH}\")\n",
    "print(f\"Model: {config['nLayers']} layers, {config['nUnits']} units, bidirectional={config['bidirectional']}\")\n",
    "print(f\"Training: {config['nBatch']} batches, batch_size={config['batchSize']}\")\n",
    "print(f\"Optimizer: SGD (momentum={config['momentum']}, nesterov={config['useNesterov']})\")\n",
    "print(f\"Learning rate: {config['lrStart']} → {config['lrEnd']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19382537",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "TRAINING CODE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ed84f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    X, y, X_lens, y_lens, days = zip(*batch)\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    return (\n",
    "        X_padded,\n",
    "        y_padded,\n",
    "        torch.stack(X_lens),\n",
    "        torch.stack(y_lens),\n",
    "        torch.stack(days),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d516cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(f\"\\nLoading data from: {DATASET_PATH}\")\n",
    "with open(DATASET_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SpeechDataset(data[\"train\"])\n",
    "test_ds = SpeechDataset(data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config['batchSize'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=config['batchSize'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(f\"\\nCreating model...\")\n",
    "model = GRUDecoder(\n",
    "    neural_dim=config['nInputFeatures'],\n",
    "    n_classes=config['nClasses'],\n",
    "    hidden_dim=config['nUnits'],\n",
    "    layer_dim=config['nLayers'],\n",
    "    nDays=len(data[\"train\"]),\n",
    "    dropout=config['dropout'],\n",
    "    device=DEVICE,\n",
    "    strideLen=config['strideLen'],\n",
    "    kernelLen=config['kernelLen'],\n",
    "    gaussianSmoothWidth=config['gaussianSmoothWidth'],\n",
    "    bidirectional=config['bidirectional'],\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using SGD with Nesterov momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_ctc = torch.nn.CTCLoss(blank=0, reduction=\"mean\", zero_infinity=True)\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config['lrStart'],\n",
    "    momentum=config['momentum'],\n",
    "    nesterov=config['useNesterov'],\n",
    "    weight_decay=config['l2_decay'],\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=config['lrEnd'] / config['lrStart'],\n",
    "    total_iters=config['nBatch'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afa688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(f\"\\nStarting training for {config['nBatch']} batches...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_list = []\n",
    "test_cer_list = []\n",
    "best_cer = None\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx in range(config['nBatch']):\n",
    "    model.train()\n",
    "\n",
    "    # Get batch\n",
    "    X, y, X_len, y_len, day_idx = next(iter(train_loader))\n",
    "    X, y, X_len, y_len, day_idx = (\n",
    "        X.to(DEVICE),\n",
    "        y.to(DEVICE),\n",
    "        X_len.to(DEVICE),\n",
    "        y_len.to(DEVICE),\n",
    "        day_idx.to(DEVICE),\n",
    "    )\n",
    "\n",
    "    # Augmentation\n",
    "    if config['whiteNoiseSD'] > 0:\n",
    "        X += torch.randn(X.shape, device=DEVICE) * config['whiteNoiseSD']\n",
    "    if config['constantOffsetSD'] > 0:\n",
    "        X += torch.randn([X.shape[0], 1, X.shape[2]], device=DEVICE) * config['constantOffsetSD']\n",
    "    if config.get('featureMaskProb', 0) > 0:\n",
    "        # Feature masking: randomly zero out individual feature values\n",
    "        mask = torch.rand_like(X) < config['featureMaskProb']\n",
    "        X = X.masked_fill(mask, 0)\n",
    "\n",
    "    # Forward\n",
    "    pred = model.forward(X, day_idx)\n",
    "    loss = loss_ctc(\n",
    "        torch.permute(pred.log_softmax(2), [1, 0, 2]),\n",
    "        y,\n",
    "        ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32),\n",
    "        y_len,\n",
    "    )\n",
    "    loss = torch.sum(loss)\n",
    "\n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluation every 500 batches (less frequent to save time)\n",
    "    if batch_idx % 500 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            all_loss = []\n",
    "            total_edit = 0\n",
    "            total_len = 0\n",
    "\n",
    "            # Evaluate on subset to save time\n",
    "            for eval_idx, (X, y, X_len, y_len, test_day_idx) in enumerate(test_loader):\n",
    "                if eval_idx >= 20:  # Only eval on first 20 batches\n",
    "                    break\n",
    "\n",
    "                X, y, X_len, y_len, test_day_idx = (\n",
    "                    X.to(DEVICE),\n",
    "                    y.to(DEVICE),\n",
    "                    X_len.to(DEVICE),\n",
    "                    y_len.to(DEVICE),\n",
    "                    test_day_idx.to(DEVICE),\n",
    "                )\n",
    "\n",
    "                pred = model.forward(X, test_day_idx)\n",
    "                loss = loss_ctc(\n",
    "                    torch.permute(pred.log_softmax(2), [1, 0, 2]),\n",
    "                    y,\n",
    "                    ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32),\n",
    "                    y_len,\n",
    "                )\n",
    "                loss = torch.sum(loss)\n",
    "                all_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "                adjusted_lens = ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32)\n",
    "                for i in range(pred.shape[0]):\n",
    "                    logits = pred[i, :adjusted_lens[i], :]\n",
    "                    decoded = torch.argmax(logits, dim=-1)\n",
    "                    decoded = torch.unique_consecutive(decoded)\n",
    "                    decoded = decoded.cpu().detach().numpy()\n",
    "                    decoded = decoded[decoded != 0]\n",
    "\n",
    "                    target = y[i, :y_len[i]].cpu().detach().numpy()\n",
    "\n",
    "                    matcher = SequenceMatcher(a=target.tolist(), b=decoded.tolist())\n",
    "                    total_edit += matcher.distance()\n",
    "                    total_len += len(target)\n",
    "\n",
    "            avg_loss = np.sum(all_loss) / len(all_loss)\n",
    "            cer = total_edit / total_len\n",
    "\n",
    "            elapsed = (time.time() - start_time) / 500 if batch_idx > 0 else 0.0\n",
    "            print(f\"batch {batch_idx:5d}, ctc loss: {avg_loss:.4f}, cer: {cer:.4f}, time/batch: {elapsed:.3f}s\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Save stats\n",
    "            test_loss_list.append(avg_loss)\n",
    "            test_cer_list.append(cer)\n",
    "\n",
    "            # Save best model\n",
    "            if best_cer is None or cer < best_cer:\n",
    "                best_cer = cer\n",
    "                torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"modelWeights.pt\"))\n",
    "                print(f\"  → New best CER: {cer:.4f}, model saved!\")\n",
    "\n",
    "            # Save stats\n",
    "            stats = {\n",
    "                \"testLoss\": np.array(test_loss_list),\n",
    "                \"testCER\": np.array(test_cer_list),\n",
    "            }\n",
    "            with open(os.path.join(OUTPUT_DIR, \"trainingStats.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best CER: {best_cer:.4f} ({best_cer*100:.2f}%)\")\n",
    "print(f\"Model saved to: {OUTPUT_DIR}/modelWeights.pt\")\n",
    "print(f\"Stats saved to: {OUTPUT_DIR}/trainingStats.pkl\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324y75dwooh",
   "metadata": {},
   "source": [
    "# Language Model Evaluation\n",
    "\n",
    "Now let's evaluate the model with a phoneme language model for improved accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leaonaabmvg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KenLM if not already installed\n",
    "try:\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing KenLM...\")\n",
    "    !pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kibu7aja84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LM module\n",
    "from neural_decoder.phoneme_lm import PhonemeLM, beam_search_decode, create_phoneme_map\n",
    "\n",
    "# Load the language model\n",
    "LM_PATH = \"phoneme_lm.arpa\"  # In notebooks folder\n",
    "phoneme_map = create_phoneme_map()\n",
    "lm = PhonemeLM(LM_PATH, phoneme_map=phoneme_map)\n",
    "\n",
    "print(f\"✓ Language Model loaded from: {LM_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls1ubtk7ym",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with Language Model\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING WITH LANGUAGE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model.eval()\n",
    "all_predictions_baseline = []\n",
    "all_predictions_lm = []\n",
    "all_targets = []\n",
    "\n",
    "LM_WEIGHT = 0.8  # Can adjust: 0.4-1.2\n",
    "BEAM_WIDTH = 10  # Can adjust: 5-50\n",
    "\n",
    "print(f\"LM Weight: {LM_WEIGHT}\")\n",
    "print(f\"Beam Width: {BEAM_WIDTH}\")\n",
    "print()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X, y, X_len, y_len, day_idx) in enumerate(test_loader):\n",
    "        X = X.to(DEVICE)\n",
    "        day_idx = day_idx.to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(X, day_idx)\n",
    "        lengths = ((X_len - config['kernelLen']) / config['strideLen']).long()\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        # Decode each sample in batch\n",
    "        for i in range(len(y)):\n",
    "            seq_len = int(lengths[i])\n",
    "            lp = log_probs[i, :seq_len, :]  # [T, V]\n",
    "            \n",
    "            # Baseline: Greedy decoding (no LM)\n",
    "            greedy = torch.argmax(lp, dim=-1).cpu().numpy()\n",
    "            decoded_baseline = []\n",
    "            prev = None\n",
    "            for tok in greedy:\n",
    "                if tok == prev or tok == 0:  # Skip repeats and blank\n",
    "                    prev = tok\n",
    "                    continue\n",
    "                decoded_baseline.append(tok)\n",
    "                prev = tok\n",
    "            all_predictions_baseline.append(decoded_baseline)\n",
    "            \n",
    "            # With LM: Beam search\n",
    "            decoded_lm = beam_search_decode(\n",
    "                lp,\n",
    "                lm=lm,\n",
    "                lm_weight=LM_WEIGHT,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                blank_id=0,\n",
    "                topk_acoustic=5\n",
    "            )\n",
    "            all_predictions_lm.append(decoded_lm)\n",
    "            \n",
    "            # Get target\n",
    "            target = y[i, :y_len[i]].cpu().numpy().tolist()\n",
    "            all_targets.append(target)\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "\n",
    "print(\"✓ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhrsv41qjrg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CER/PER\n",
    "def compute_error_rate(predictions, targets):\n",
    "    total_edit = 0\n",
    "    total_len = 0\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        matcher = SequenceMatcher(a=target, b=pred)\n",
    "        total_edit += matcher.distance()\n",
    "        total_len += len(target)\n",
    "    return total_edit / total_len if total_len > 0 else 0.0\n",
    "\n",
    "cer_baseline = compute_error_rate(all_predictions_baseline, all_targets)\n",
    "cer_lm = compute_error_rate(all_predictions_lm, all_targets)\n",
    "improvement = (cer_baseline - cer_lm) / cer_baseline * 100  # % improvement\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBaseline (Greedy):\")\n",
    "print(f\"  CER/PER: {cer_baseline:.4f} ({cer_baseline*100:.2f}%)\")\n",
    "print(f\"\\nWith Language Model:\")\n",
    "print(f\"  CER/PER: {cer_lm:.4f} ({cer_lm*100:.2f}%)\")\n",
    "print(f\"  Improvement: {improvement:.2f}% relative\")\n",
    "print(f\"  Absolute gain: {(cer_baseline - cer_lm)*100:.2f} percentage points\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Language Model improved accuracy by {improvement:.1f}%!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
