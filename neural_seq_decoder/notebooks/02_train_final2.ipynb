{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbec367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training script for the final2 model using NeuralDecoder architecture\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a357504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from omegaconf import OmegaConf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_decoder.neural_decoder_trainer import DataModule\n",
    "from neural_decoder.final2_model import NeuralDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f45972",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"src/neural_decoder/conf/decoder/final2.yaml\"\n",
    "DATASET_NAME = \"competition_data\"\n",
    "OUTPUT_DIR = \"results/final2_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df305bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL2 MODEL TRAINING\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ff699",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(CONFIG_PATH)\n",
    "print(f\"\\nLoaded configuration from: {CONFIG_PATH}\")\n",
    "print(f\"Model variant: {config.variant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7698c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.get('seed', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = DataModule(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    batch_size=config.batchSize,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralDecoder(\n",
    "    conv_size=config.get('conv_size', 1024),\n",
    "    conv_kernel1=config.get('conv_kernel1', 7),\n",
    "    conv_kernel2=config.get('conv_kernel2', 3),\n",
    "    conv_g1=config.get('conv_g1', 256),\n",
    "    conv_g2=config.get('conv_g2', 1),\n",
    "    hidden_size=config.get('hidden_size', 512),\n",
    "    encoder_n_layer=config.get('encoder_n_layer', 5),\n",
    "    decoder_n_layer=config.get('decoder_n_layer', 5),\n",
    "    decoders=config.get('decoders', ['al', 'ph']),\n",
    "    update_probs=config.get('update_probs', 0.7),\n",
    "    al_loss_weight=config.get('al_loss_weight', 0.5),\n",
    "    peak_lr=config.get('peak_lr', 1e-4),\n",
    "    last_lr=config.get('last_lr', 1e-6),\n",
    "    beta_1=config.get('beta_1', 0.9),\n",
    "    beta_2=config.get('beta_2', 0.95),\n",
    "    weight_decay=config.get('weight_decay', 0.1),\n",
    "    eps=config.get('eps', 1e-08),\n",
    "    lr_warmup_perc=config.get('lr_warmup_perc', 0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=OUTPUT_DIR,\n",
    "    filename=\"final2-{epoch:02d}-{wer:.4f}\",\n",
    "    monitor=\"wer\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir=OUTPUT_DIR,\n",
    "    name=\"final2_logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f57e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=config.get('max_epochs', 100),\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, lr_monitor],\n",
    "    gradient_clip_val=config.get('gradient_clip_val', 1.0),\n",
    "    accumulate_grad_batches=config.get('accumulate_grad_batches', 1),\n",
    "    precision=config.get('precision', '32'),\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b71406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nStarting training for {config.get('max_epochs', 100)} epochs...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48685130",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best model saved to: {checkpoint_callback.best_model_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qkgfqvwn4vr",
   "metadata": {},
   "source": [
    "# Language Model Evaluation\n",
    "\n",
    "Now let's evaluate the model with a phoneme language model for improved accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40g2geiz0p5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KenLM if not already installed\n",
    "try:\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing KenLM...\")\n",
    "    !pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "    import kenlm\n",
    "    print(\"✓ KenLM installed successfully\")\n",
    "\n",
    "# Import LM module\n",
    "from neural_decoder.phoneme_lm import PhonemeLM, beam_search_decode, create_phoneme_map\n",
    "from edit_distance import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "# Load the language model\n",
    "LM_PATH = \"phoneme_lm.arpa\"\n",
    "phoneme_map = create_phoneme_map()\n",
    "lm = PhonemeLM(LM_PATH, phoneme_map=phoneme_map)\n",
    "print(f\"✓ Language Model loaded from: {LM_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jycizfoxsbr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint\n",
    "best_model = NeuralDecoder.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path\n",
    ")\n",
    "best_model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "print(f\"✓ Loaded best model from: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mp4ynu2a3pg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with Language Model\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING WITH LANGUAGE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_predictions_baseline = []\n",
    "all_predictions_lm = []\n",
    "all_targets = []\n",
    "\n",
    "LM_WEIGHT = 0.8  # Can adjust: 0.4-1.2\n",
    "BEAM_WIDTH = 10  # Can adjust: 5-50\n",
    "\n",
    "print(f\"LM Weight: {LM_WEIGHT}\")\n",
    "print(f\"Beam Width: {BEAM_WIDTH}\\n\")\n",
    "\n",
    "# Get test dataloader\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader):\n",
    "        # Move batch to device\n",
    "        x = batch['x'].to(device)\n",
    "        day_idx = batch['dayIndex'].to(device)\n",
    "        y = batch['y']\n",
    "        y_len = batch['yLen']\n",
    "        \n",
    "        # Forward pass - get phoneme predictions\n",
    "        outputs = best_model(x, day_idx)\n",
    "        logits = outputs['ph']  # Phoneme logits\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        # Decode each sample\n",
    "        for i in range(len(y)):\n",
    "            lp = log_probs[i]  # [T, V]\n",
    "            \n",
    "            # Baseline: Greedy decoding\n",
    "            greedy = torch.argmax(lp, dim=-1).cpu().numpy()\n",
    "            decoded_baseline = []\n",
    "            prev = None\n",
    "            for tok in greedy:\n",
    "                if tok == prev or tok == 0:\n",
    "                    prev = tok\n",
    "                    continue\n",
    "                decoded_baseline.append(tok)\n",
    "                prev = tok\n",
    "            all_predictions_baseline.append(decoded_baseline)\n",
    "            \n",
    "            # With LM: Beam search\n",
    "            decoded_lm = beam_search_decode(\n",
    "                lp,\n",
    "                lm=lm,\n",
    "                lm_weight=LM_WEIGHT,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                blank_id=0,\n",
    "                topk_acoustic=5\n",
    "            )\n",
    "            all_predictions_lm.append(decoded_lm)\n",
    "            \n",
    "            # Get target\n",
    "            target = y[i, :y_len[i]].cpu().numpy().tolist()\n",
    "            all_targets.append(target)\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {batch_idx + 1}/{len(test_dataloader)} batches\")\n",
    "\n",
    "print(\"✓ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p481lhgrleq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PER\n",
    "def compute_error_rate(predictions, targets):\n",
    "    total_edit = 0\n",
    "    total_len = 0\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        matcher = SequenceMatcher(a=target, b=pred)\n",
    "        total_edit += matcher.distance()\n",
    "        total_len += len(target)\n",
    "    return total_edit / total_len if total_len > 0 else 0.0\n",
    "\n",
    "per_baseline = compute_error_rate(all_predictions_baseline, all_targets)\n",
    "per_lm = compute_error_rate(all_predictions_lm, all_targets)\n",
    "improvement = (per_baseline - per_lm) / per_baseline * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBaseline (Greedy):\")\n",
    "print(f\"  PER: {per_baseline:.4f} ({per_baseline*100:.2f}%)\")\n",
    "print(f\"\\nWith Language Model:\")\n",
    "print(f\"  PER: {per_lm:.4f} ({per_lm*100:.2f}%)\")\n",
    "print(f\"  Improvement: {improvement:.2f}% relative\")\n",
    "print(f\"  Absolute gain: {(per_baseline - per_lm)*100:.2f} percentage points\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Language Model improved accuracy by {improvement:.1f}%!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
