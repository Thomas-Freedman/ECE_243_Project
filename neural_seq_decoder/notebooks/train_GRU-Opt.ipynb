{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23de171f",
      "metadata": {
        "id": "23de171f"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c84d42f1",
      "metadata": {
        "id": "c84d42f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import yaml\n",
        "import numpy as np\n",
        "import torch\n",
        "from edit_distance import SequenceMatcher\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2QBo0ycjIpmM",
      "metadata": {
        "id": "2QBo0ycjIpmM"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numbers\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class WhiteNoise(nn.Module):\n",
        "    def __init__(self, std=0.1):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn_like(x) * self.std\n",
        "        return x + noise\n",
        "\n",
        "class MeanDriftNoise(nn.Module):\n",
        "    def __init__(self, std=0.1):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, C = x.shape\n",
        "        noise = torch.randn(1, C) * self.std\n",
        "        return x + noise\n",
        "\n",
        "class FeatureMasking(nn.Module):\n",
        "    \"\"\"\n",
        "    Randomly masks out features (neural channels) to zero with a given probability.\n",
        "    This helps the model not rely too heavily on specific channels and improves robustness.\n",
        "\n",
        "    Arguments:\n",
        "        mask_prob (float): Probability of masking each individual feature value (0.0 to 1.0)\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.mask_prob = mask_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.mask_prob <= 0 or not self.training:\n",
        "            return x\n",
        "        # Create random mask: each element has mask_prob chance of being masked\n",
        "        mask = torch.rand_like(x) < self.mask_prob\n",
        "        # Set masked elements to zero\n",
        "        return x.masked_fill(mask, 0)\n",
        "\n",
        "class GaussianSmoothing(nn.Module):\n",
        "    def __init__(self, channels, kernel_size, sigma, dim=2):\n",
        "        super(GaussianSmoothing, self).__init__()\n",
        "        if isinstance(kernel_size, numbers.Number):\n",
        "            kernel_size = [kernel_size] * dim\n",
        "        if isinstance(sigma, numbers.Number):\n",
        "            sigma = [sigma] * dim\n",
        "\n",
        "        kernel = 1\n",
        "        meshgrids = torch.meshgrid(\n",
        "            [torch.arange(size, dtype=torch.float32) for size in kernel_size]\n",
        "        )\n",
        "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
        "            mean = (size - 1) / 2\n",
        "            kernel *= (\n",
        "                1\n",
        "                / (std * math.sqrt(2 * math.pi))\n",
        "                * torch.exp(-(((mgrid - mean) / std) ** 2) / 2)\n",
        "            )\n",
        "\n",
        "        kernel = kernel / torch.sum(kernel)\n",
        "\n",
        "        kernel = kernel.view(1, 1, *kernel.size())\n",
        "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
        "\n",
        "        self.register_buffer(\"weight\", kernel)\n",
        "        self.groups = channels\n",
        "\n",
        "        if dim == 1:\n",
        "            self.conv = F.conv1d\n",
        "        elif dim == 2:\n",
        "            self.conv = F.conv2d\n",
        "        elif dim == 3:\n",
        "            self.conv = F.conv3d\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                \"Only 1, 2 and 3 dimensions are supported. Received {}.\".format(dim)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input, weight=self.weight, groups=self.groups, padding=\"same\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "yyvnELhmIhQ5",
      "metadata": {
        "id": "yyvnELhmIhQ5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.n_days = len(data)\n",
        "        self.n_trials = sum([len(d[\"sentenceDat\"]) for d in data])\n",
        "\n",
        "        self.neural_feats = []\n",
        "        self.phone_seqs = []\n",
        "        self.neural_time_bins = []\n",
        "        self.phone_seq_lens = []\n",
        "        self.days = []\n",
        "        for day in range(self.n_days):\n",
        "            for trial in range(len(data[day][\"sentenceDat\"])):\n",
        "                self.neural_feats.append(data[day][\"sentenceDat\"][trial])\n",
        "                self.phone_seqs.append(data[day][\"phonemes\"][trial])\n",
        "                self.neural_time_bins.append(data[day][\"sentenceDat\"][trial].shape[0])\n",
        "                self.phone_seq_lens.append(data[day][\"phoneLens\"][trial])\n",
        "                self.days.append(day)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_trials\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        neural_feats = torch.tensor(self.neural_feats[idx], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            neural_feats = self.transform(neural_feats)\n",
        "\n",
        "        return (\n",
        "            neural_feats,\n",
        "            torch.tensor(self.phone_seqs[idx], dtype=torch.int32),\n",
        "            torch.tensor(self.neural_time_bins[idx], dtype=torch.int32),\n",
        "            torch.tensor(self.phone_seq_lens[idx], dtype=torch.int32),\n",
        "            torch.tensor(self.days[idx], dtype=torch.int64),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "257991e3",
      "metadata": {
        "id": "257991e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class GRUDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        neural_dim,\n",
        "        n_classes,\n",
        "        hidden_dim,\n",
        "        layer_dim,\n",
        "        nDays=24,\n",
        "        dropout=0,\n",
        "        device=\"cuda\",\n",
        "        strideLen=4,\n",
        "        kernelLen=14,\n",
        "        gaussianSmoothWidth=0,\n",
        "        bidirectional=False,\n",
        "    ):\n",
        "        super(GRUDecoder, self).__init__()\n",
        "\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.neural_dim = neural_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.nDays = nDays\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        self.strideLen = strideLen\n",
        "        self.kernelLen = kernelLen\n",
        "        self.gaussianSmoothWidth = gaussianSmoothWidth\n",
        "        self.bidirectional = bidirectional\n",
        "        self.inputLayerNonlinearity = torch.nn.Softsign()\n",
        "        self.unfolder = torch.nn.Unfold(\n",
        "            (self.kernelLen, 1), dilation=1, padding=0, stride=self.strideLen\n",
        "        )\n",
        "        self.gaussianSmoother = GaussianSmoothing(\n",
        "            neural_dim, 20, self.gaussianSmoothWidth, dim=1\n",
        "        )\n",
        "        self.dayWeights = torch.nn.Parameter(torch.randn(nDays, neural_dim, neural_dim))\n",
        "        self.dayBias = torch.nn.Parameter(torch.zeros(nDays, 1, neural_dim))\n",
        "\n",
        "        for x in range(nDays):\n",
        "            self.dayWeights.data[x, :, :] = torch.eye(neural_dim)\n",
        "\n",
        "        self.gru_decoder = nn.GRU(\n",
        "            (neural_dim) * self.kernelLen,\n",
        "            hidden_dim,\n",
        "            layer_dim,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout,\n",
        "            bidirectional=self.bidirectional,\n",
        "        )\n",
        "\n",
        "        for name, param in self.gru_decoder.named_parameters():\n",
        "            if \"weight_hh\" in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "            if \"weight_ih\" in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "        for x in range(nDays):\n",
        "            setattr(self, \"inpLayer\" + str(x), nn.Linear(neural_dim, neural_dim))\n",
        "\n",
        "        for x in range(nDays):\n",
        "            thisLayer = getattr(self, \"inpLayer\" + str(x))\n",
        "            thisLayer.weight = torch.nn.Parameter(\n",
        "                thisLayer.weight + torch.eye(neural_dim)\n",
        "            )\n",
        "\n",
        "        if self.bidirectional:\n",
        "            self.fc_decoder_out = nn.Linear(\n",
        "                hidden_dim * 2, n_classes + 1\n",
        "            ) \n",
        "        else:\n",
        "            self.fc_decoder_out = nn.Linear(hidden_dim, n_classes + 1)  \n",
        "\n",
        "    def forward(self, neuralInput, dayIdx):\n",
        "        neuralInput = torch.permute(neuralInput, (0, 2, 1))\n",
        "        neuralInput = self.gaussianSmoother(neuralInput)\n",
        "        neuralInput = torch.permute(neuralInput, (0, 2, 1))\n",
        "\n",
        "        dayWeights = torch.index_select(self.dayWeights, 0, dayIdx)\n",
        "        transformedNeural = torch.einsum(\n",
        "            \"btd,bdk->btk\", neuralInput, dayWeights\n",
        "        ) + torch.index_select(self.dayBias, 0, dayIdx)\n",
        "        transformedNeural = self.inputLayerNonlinearity(transformedNeural)\n",
        "\n",
        "        stridedInputs = torch.permute(\n",
        "            self.unfolder(\n",
        "                torch.unsqueeze(torch.permute(transformedNeural, (0, 2, 1)), 3)\n",
        "            ),\n",
        "            (0, 2, 1),\n",
        "        )\n",
        "\n",
        "        if self.bidirectional:\n",
        "            h0 = torch.zeros(\n",
        "                self.layer_dim * 2,\n",
        "                transformedNeural.size(0),\n",
        "                self.hidden_dim,\n",
        "                device=self.device,\n",
        "            ).requires_grad_()\n",
        "        else:\n",
        "            h0 = torch.zeros(\n",
        "                self.layer_dim,\n",
        "                transformedNeural.size(0),\n",
        "                self.hidden_dim,\n",
        "                device=self.device,\n",
        "            ).requires_grad_()\n",
        "\n",
        "        hid, _ = self.gru_decoder(stridedInputs, h0.detach())\n",
        "\n",
        "        seq_out = self.fc_decoder_out(hid)\n",
        "        return seq_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "zRTDse7fI2LE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRTDse7fI2LE",
        "outputId": "c9b0583a-facf-4d2d-bf96-dde1d8104aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28c06b4",
      "metadata": {
        "id": "a28c06b4"
      },
      "outputs": [],
      "source": [
        "CONFIG_PATH = \"/content/drive/MyDrive/ECE_243A/final.yaml\"\n",
        "DATASET_PATH = os.path.expanduser(\"/content/drive/MyDrive/ECE_243A/ptDecoder_ctc\")\n",
        "OUTPUT_DIR = os.path.expanduser(\"/content/drive/MyDrive/ECE_243A\")\n",
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0bed6e81",
      "metadata": {
        "id": "0bed6e81"
      },
      "outputs": [],
      "source": [
        "# Load config\n",
        "with open(CONFIG_PATH, 'r') as f:\n",
        "    config = yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a2f98eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2f98eb",
        "lines_to_next_cell": 1,
        "outputId": "b8de0342-f6c0-463f-dc86-4bdd21580c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded configuration from: /content/drive/MyDrive/ECE_243A/final.yaml\n",
            "Model: 5 layers, 1024 units, bidirectional=True\n",
            "Training: 15000 batches, batch_size=64\n",
            "Optimizer: SGD (momentum=0.9, nesterov=True)\n",
            "Learning rate: 0.02 → 0.005\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nLoaded configuration from: {CONFIG_PATH}\")\n",
        "print(f\"Model: {config['nLayers']} layers, {config['nUnits']} units, bidirectional={config['bidirectional']}\")\n",
        "print(f\"Training: {config['nBatch']} batches, batch_size={config['batchSize']}\")\n",
        "print(f\"Optimizer: SGD (momentum={config['momentum']}, nesterov={config['useNesterov']})\")\n",
        "print(f\"Learning rate: {config['lrStart']} → {config['lrEnd']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kibu7aja84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kibu7aja84",
        "outputId": "27d7310d-727d-4f7a-bd16-3482d5410610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language Model loaded from: /content/drive/MyDrive/ECE_243A/phoneme_lm.arpa\n"
          ]
        }
      ],
      "source": [
        "# Import LM module\n",
        "# from neural_decoder.phoneme_lm import PhonemeLM, beam_search_decode, create_phoneme_map\n",
        "try:\n",
        "  import kenlm\n",
        "  LM_AVAILABLE = True\n",
        "except ImportError:\n",
        "  print(\"KenLM not available.\")\n",
        "\n",
        "class PhonemeLM:\n",
        "    def __init__(self, lm_path: str, phoneme_map: dict = None):\n",
        "        if not LM_AVAILABLE:\n",
        "            raise RuntimeError(\"kenlm python bindings not available. Install kenlm to use phoneme LM.\")\n",
        "        if not os.path.exists(lm_path):\n",
        "            raise FileNotFoundError(f\"LM file not found: {lm_path}\")\n",
        "        self.model = kenlm.Model(lm_path)\n",
        "        self.phoneme_map = phoneme_map or {}\n",
        "        self._score_cache = {}\n",
        "\n",
        "    @staticmethod\n",
        "    def _tokens_to_str(tokens):\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    def id_sequence_to_tokens(self, id_seq):\n",
        "        tokens = []\n",
        "        for i in id_seq:\n",
        "            \n",
        "            t = self.phoneme_map.get(int(i), None)\n",
        "            if t is None:\n",
        "                t = f\"PH{int(i)}\"\n",
        "            tokens.append(t)\n",
        "        return tokens\n",
        "\n",
        "    def score(self, id_seq):\n",
        "        key = tuple(id_seq)\n",
        "        if key in self._score_cache:\n",
        "            return self._score_cache[key]\n",
        "        tokens = self.id_sequence_to_tokens(id_seq)\n",
        "        s = self.model.score(self._tokens_to_str(tokens), bos=False, eos=False)\n",
        "        self._score_cache[key] = float(s)\n",
        "        return float(s)\n",
        "\n",
        "    def clear_cache(self):\n",
        "        self._score_cache.clear()\n",
        "\n",
        "\n",
        "def beam_search(log_probs, lm_wrapper: PhonemeLM = None, lm_weight=0.8, beam_width=8, blank_id=0, topk_acoustic=5):\n",
        "\n",
        "    if isinstance(log_probs, torch.Tensor):\n",
        "        lp = log_probs.detach().cpu().numpy()\n",
        "    else:\n",
        "        lp = np.array(log_probs)\n",
        "    T, V = lp.shape\n",
        "\n",
        "    beams = [([], 0.0, 0.0)]\n",
        "    for t in range(T):\n",
        "        step = lp[t]  \n",
        "        topk_idx = np.argsort(step)[-topk_acoustic:][::-1]  \n",
        "        new_beams = {}\n",
        "        for seq, a_score, l_score in beams:\n",
        "            for idx in topk_idx:\n",
        "                token_logp = float(step[idx])\n",
        "                if idx == blank_id:\n",
        "                    new_seq = tuple(seq)\n",
        "                    new_a = a_score + token_logp\n",
        "                    new_l = l_score  \n",
        "                else:\n",
        "                    new_seq = tuple(list(seq) + [int(idx)])\n",
        "                    new_a = a_score + token_logp\n",
        "                    if lm_wrapper is not None:\n",
        "                        lm_s = lm_wrapper.score(new_seq)\n",
        "                        new_l = lm_s\n",
        "                    else:\n",
        "                        new_l = 0.0\n",
        "\n",
        "                combined = new_a + (lm_weight * new_l)\n",
        "                if new_seq not in new_beams or combined > new_beams[new_seq][0]:\n",
        "                    new_beams[new_seq] = (combined, new_a, new_l)\n",
        "\n",
        "        sorted_beams = sorted(new_beams.items(), key=lambda x: x[1][0], reverse=True)[:beam_width]\n",
        "        beams = [(list(k), v[1], v[2]) for k, v in sorted_beams]\n",
        "\n",
        "    best = max(beams, key=lambda b: b[1] + lm_weight * b[2])\n",
        "    decoded = best[0]\n",
        "    collapsed = []\n",
        "    prev = None\n",
        "    for tok in decoded:\n",
        "        if tok == prev:\n",
        "            prev = tok\n",
        "            continue\n",
        "        if tok != blank_id:\n",
        "            collapsed.append(tok)\n",
        "        prev = tok\n",
        "    return collapsed\n",
        "\n",
        "def load_phoneme_map(path, n_classes):\n",
        "    if path is None:\n",
        "        return {i: f\"PH{i}\" for i in range(1, n_classes + 1)}\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Phoneme map path not found: {path}. Falling back to synthetic tokens.\")\n",
        "        return {i: f\"PH{i}\" for i in range(1, n_classes + 1)}\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = [l.strip() for l in f if l.strip()]\n",
        "            m = {}\n",
        "            for idx, tok in enumerate(lines, start=1):\n",
        "                m[idx] = tok\n",
        "            for i in range(1, n_classes + 1):\n",
        "                if i not in m:\n",
        "                    m[i] = f\"PH{i}\"\n",
        "            return m\n",
        "    except Exception:\n",
        "        pass\n",
        "    return {i: f\"PH{i}\" for i in range(1, n_classes + 1)}\n",
        "\n",
        "# Load the language model\n",
        "LM_PATH = \"/content/drive/MyDrive/ECE_243A/phoneme_lm.arpa\"\n",
        "PHONEME_MAP_PATH = \"/content/drive/MyDrive/ECE_243A/phoneme_map.txt\"\n",
        "phoneme_map = load_phoneme_map(PHONEME_MAP_PATH, 40)\n",
        "lm = PhonemeLM(LM_PATH, phoneme_map=phoneme_map)\n",
        "\n",
        "LM_WEIGHT = 0.6  \n",
        "BEAM_WIDTH = 10 \n",
        "\n",
        "print(f\"Language Model loaded from: {LM_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19382537",
      "metadata": {
        "id": "19382537"
      },
      "source": [
        "============================================================================\n",
        "TRAINING CODE\n",
        "============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f82ed84f",
      "metadata": {
        "id": "f82ed84f",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    X, y, X_lens, y_lens, days = zip(*batch)\n",
        "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
        "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
        "    return (\n",
        "        X_padded,\n",
        "        y_padded,\n",
        "        torch.stack(X_lens),\n",
        "        torch.stack(y_lens),\n",
        "        torch.stack(days),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e9d516cb",
      "metadata": {
        "id": "e9d516cb"
      },
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "655a92a6",
      "metadata": {
        "id": "655a92a6"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "torch.manual_seed(config['seed'])\n",
        "np.random.seed(config['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b5f7a457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5f7a457",
        "outputId": "289a7924-3626-402e-8454-5d0e05106bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading data from: /content/drive/MyDrive/ECE_243A/ptDecoder_ctc\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "print(f\"\\nLoading data from: {DATASET_PATH}\")\n",
        "with open(DATASET_PATH, \"rb\") as f:\n",
        "    data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f161ae36",
      "metadata": {
        "id": "f161ae36"
      },
      "outputs": [],
      "source": [
        "train_ds = SpeechDataset(data[\"train\"])\n",
        "test_ds = SpeechDataset(data[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6a34b46f",
      "metadata": {
        "id": "6a34b46f"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=config['batchSize'],\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=config['batchSize'],\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2396d9b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2396d9b4",
        "outputId": "0b5711b5-314e-4d3b-d033-a0ae56daf1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 8780\n",
            "Test samples: 880\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train samples: {len(train_ds)}\")\n",
        "print(f\"Test samples: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b72e3b40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b72e3b40",
        "outputId": "d2749be0-9834-4e64-917c-34d3ce51ce2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "print(f\"\\nCreating model...\")\n",
        "model = GRUDecoder(\n",
        "    neural_dim=config['nInputFeatures'],\n",
        "    n_classes=config['nClasses'],\n",
        "    hidden_dim=config['nUnits'],\n",
        "    layer_dim=config['nLayers'],\n",
        "    nDays=len(data[\"train\"]),\n",
        "    dropout=config['dropout'],\n",
        "    device=DEVICE,\n",
        "    strideLen=config['strideLen'],\n",
        "    kernelLen=config['kernelLen'],\n",
        "    gaussianSmoothWidth=config['gaussianSmoothWidth'],\n",
        "    bidirectional=config['bidirectional'],\n",
        ").to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fe7fed1a",
      "metadata": {
        "id": "fe7fed1a"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "loss_ctc = torch.nn.CTCLoss(blank=0, reduction=\"mean\", zero_infinity=True)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=config['lrStart'],\n",
        "    momentum=config['momentum'],\n",
        "    nesterov=config['useNesterov'],\n",
        "    weight_decay=config['l2_decay'],\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
        "    optimizer,\n",
        "    gamma=0.9995\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "61afa688",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61afa688",
        "outputId": "3c8ef570-c20d-4127-fdd8-63def75bcbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for 15000 batches...\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print(f\"\\nStarting training for {config['nBatch']} batches...\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8fac6b44",
      "metadata": {
        "id": "8fac6b44"
      },
      "outputs": [],
      "source": [
        "test_loss_list = []\n",
        "test_cer_list = []\n",
        "best_cer = None\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0e81321b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "0e81321b",
        "outputId": "fcd303fd-d142-4ab5-cb94-f286eedf8203"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2981364804.py:111: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /pytorch/aten/src/ATen/native/Convolution.cpp:1031.)\n",
            "  return self.conv(input, weight=self.weight, groups=self.groups, padding=\"same\")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-284504303.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for batch_idx in range(config['nBatch']):\n",
        "    model.train()\n",
        "\n",
        "    # Get batch\n",
        "    X, y, X_len, y_len, day_idx = next(iter(train_loader))\n",
        "    X, y, X_len, y_len, day_idx = (\n",
        "        X.to(DEVICE),\n",
        "        y.to(DEVICE),\n",
        "        X_len.to(DEVICE),\n",
        "        y_len.to(DEVICE),\n",
        "        day_idx.to(DEVICE),\n",
        "    )\n",
        "\n",
        "    # Augmentation\n",
        "    if config['whiteNoiseSD'] > 0:\n",
        "        X += torch.randn(X.shape, device=DEVICE) * config['whiteNoiseSD']\n",
        "    if config['constantOffsetSD'] > 0:\n",
        "        X += torch.randn([X.shape[0], 1, X.shape[2]], device=DEVICE) * config['constantOffsetSD']\n",
        "    if config.get('featureMaskProb', 0) > 0:\n",
        "        # Feature masking: randomly zero out individual feature values\n",
        "        mask = torch.rand_like(X) < config['featureMaskProb']\n",
        "        X = X.masked_fill(mask, 0)\n",
        "\n",
        "    # Forward\n",
        "    pred = model.forward(X, day_idx)\n",
        "    loss = loss_ctc(\n",
        "        torch.permute(pred.log_softmax(2), [1, 0, 2]),\n",
        "        y,\n",
        "        ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32),\n",
        "        y_len,\n",
        "    )\n",
        "    loss = torch.sum(loss)\n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    # Evaluation every 500 batches (less frequent to save time)\n",
        "    if batch_idx % 500 == 0:\n",
        "        with torch.no_grad():\n",
        "          model.eval()\n",
        "          all_loss = []\n",
        "          total_edit = 0\n",
        "          total_len = 0\n",
        "\n",
        "          for eval_idx, (X, y, X_len, y_len, test_day_idx) in enumerate(test_loader):\n",
        "              if eval_idx >= 20:\n",
        "                  break\n",
        "\n",
        "              X, y, X_len, y_len, test_day_idx = (\n",
        "                  X.to(DEVICE),\n",
        "                  y.to(DEVICE),\n",
        "                  X_len.to(DEVICE),\n",
        "                  y_len.to(DEVICE),\n",
        "                  test_day_idx.to(DEVICE),\n",
        "              )\n",
        "\n",
        "              pred = model.forward(X, test_day_idx)\n",
        "              loss = loss_ctc(\n",
        "                  torch.permute(pred.log_softmax(2), [1, 0, 2]),\n",
        "                  y,\n",
        "                  ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32),\n",
        "                  y_len,\n",
        "              )\n",
        "              loss = torch.sum(loss)\n",
        "              all_loss.append(loss.cpu().item())\n",
        "\n",
        "              # CTC-adjusted frame lengths\n",
        "              adjusted_lens = ((X_len - config['kernelLen']) / config['strideLen']).to(torch.int32)\n",
        "\n",
        "              for i in range(pred.shape[0]):\n",
        "                  T = adjusted_lens[i].item()\n",
        "                  logits = pred[i, :T, :]\n",
        "\n",
        "                  # LM-aware beam search\n",
        "                  decoded = beam_search(\n",
        "                      logits,\n",
        "                      lm_wrapper=lm,\n",
        "                      lm_weight=LM_WEIGHT,\n",
        "                      beam_width=BEAM_WIDTH,\n",
        "                      blank_id=0\n",
        "                  )\n",
        "\n",
        "                  # Convert to lists for edit distance\n",
        "                  decoded = list(decoded)\n",
        "                  target = y[i, :y_len[i]].cpu().tolist()\n",
        "\n",
        "                  matcher = SequenceMatcher(a=target, b=decoded)\n",
        "                  total_edit += matcher.distance()\n",
        "                  total_len += len(target)\n",
        "\n",
        "          avg_loss = np.sum(all_loss) / len(all_loss)\n",
        "          cer = total_edit / total_len\n",
        "\n",
        "          elapsed = (time.time() - start_time) / 500 if batch_idx > 0 else 0.0\n",
        "          print(f\"batch {batch_idx:5d}, ctc loss: {avg_loss:.4f}, cer: {cer:.4f}, time/batch: {elapsed:.3f}s\")\n",
        "          start_time = time.time()\n",
        "\n",
        "          # Save stats\n",
        "          test_loss_list.append(avg_loss)\n",
        "          test_cer_list.append(cer)\n",
        "\n",
        "          # Track best model\n",
        "          if best_cer is None or cer < best_cer:\n",
        "              best_cer = cer\n",
        "              torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"modelWeights.pt\"))\n",
        "              print(f\"  → New best CER: {cer:.4f}, model saved!\")\n",
        "\n",
        "          # Write stats\n",
        "          stats = {\n",
        "              \"testLoss\": np.array(test_loss_list),\n",
        "              \"testCER\": np.array(test_cer_list),\n",
        "          }\n",
        "          with open(os.path.join(OUTPUT_DIR, \"trainingStats.pkl\"), \"wb\") as f:\n",
        "              pickle.dump(stats, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad1f556",
      "metadata": {
        "id": "5ad1f556"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Best CER: {best_cer:.4f} ({best_cer*100:.2f}%)\")\n",
        "print(f\"Model saved to: {OUTPUT_DIR}/modelWeights.pt\")\n",
        "print(f\"Stats saved to: {OUTPUT_DIR}/trainingStats.pkl\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324y75dwooh",
      "metadata": {
        "id": "324y75dwooh"
      },
      "source": [
        "# Language Model Evaluation\n",
        "\n",
        "Now let's evaluate the model with a phoneme language model for improved accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "leaonaabmvg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leaonaabmvg",
        "outputId": "e8ee8d1d-8477-4ee5-cacb-518f6c168a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ KenLM already installed\n"
          ]
        }
      ],
      "source": [
        "# Install KenLM if not already installed\n",
        "try:\n",
        "    import kenlm\n",
        "    print(\"✓ KenLM already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing KenLM...\")\n",
        "    !pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "    import kenlm\n",
        "    print(\"✓ KenLM installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ls1ubtk7ym",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls1ubtk7ym",
        "outputId": "7ca5a1b5-2ded-45a9-a807-727c2047d0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EVALUATING WITH LANGUAGE MODEL\n",
            "======================================================================\n",
            "LM Weight: 0.2\n",
            "Beam Width: 8\n",
            "\n",
            "  Processed 10/14 batches\n",
            "✓ Evaluation complete!\n"
          ]
        }
      ],
      "source": [
        "# Evaluate with Language Model\n",
        "print(\"=\" * 70)\n",
        "print(\"EVALUATING WITH LANGUAGE MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model_test = GRUDecoder(\n",
        "    neural_dim=config['nInputFeatures'],\n",
        "    n_classes=config['nClasses'],\n",
        "    hidden_dim=512,\n",
        "    layer_dim=3,\n",
        "    nDays=len(data[\"train\"]),\n",
        "    dropout=config['dropout'],\n",
        "    device=DEVICE,\n",
        "    strideLen=config['strideLen'],\n",
        "    kernelLen=config['kernelLen'],\n",
        "    gaussianSmoothWidth=config['gaussianSmoothWidth'],\n",
        "    bidirectional=config['bidirectional'],\n",
        ").to(DEVICE)\n",
        "model_test.load_state_dict(torch.load(\"/content/drive/MyDrive/ECE_243A/GRU-Opt-BEST.pt\", map_location=\"cpu\"))\n",
        "\n",
        "model_test.eval()\n",
        "all_predictions_baseline = []\n",
        "all_predictions_lm = []\n",
        "all_targets = []\n",
        "\n",
        "LM_WEIGHT_TEST = 0.2\n",
        "BEAM_WIDTH_TEST = 8\n",
        "\n",
        "print(f\"LM Weight: {LM_WEIGHT_TEST}\")\n",
        "print(f\"Beam Width: {BEAM_WIDTH_TEST}\")\n",
        "print()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (X, y, X_len, y_len, day_idx) in enumerate(test_loader):\n",
        "        X = X.to(DEVICE)\n",
        "        day_idx = day_idx.to(DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model_test(X, day_idx)\n",
        "        lengths = ((X_len - config['kernelLen']) / config['strideLen']).long()\n",
        "        log_probs = torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "        # Decode each sample in batch\n",
        "        for i in range(len(y)):\n",
        "            seq_len = int(lengths[i])\n",
        "            lp = log_probs[i, :seq_len, :]  # [T, V]\n",
        "\n",
        "            # Baseline: Greedy decoding (no LM)\n",
        "            greedy = torch.argmax(lp, dim=-1).cpu().numpy()\n",
        "            decoded_baseline = []\n",
        "            prev = None\n",
        "            for tok in greedy:\n",
        "                if tok == prev or tok == 0:  # Skip repeats and blank\n",
        "                    prev = tok\n",
        "                    continue\n",
        "                decoded_baseline.append(tok)\n",
        "                prev = tok\n",
        "            all_predictions_baseline.append(decoded_baseline)\n",
        "\n",
        "            # With LM: Beam search\n",
        "            decoded_lm = beam_search(\n",
        "                lp,\n",
        "                lm_wrapper=lm,\n",
        "                lm_weight=LM_WEIGHT_TEST,\n",
        "                beam_width=BEAM_WIDTH_TEST,\n",
        "                blank_id=0,\n",
        "                topk_acoustic=5\n",
        "            )\n",
        "            all_predictions_lm.append(decoded_lm)\n",
        "\n",
        "            # Get target\n",
        "            target = y[i, :y_len[i]].cpu().numpy().tolist()\n",
        "            all_targets.append(target)\n",
        "\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(f\"  Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
        "\n",
        "print(\"✓ Evaluation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "mhrsv41qjrg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhrsv41qjrg",
        "outputId": "56f81a78-d026-4f56-dc75-87e80e0067d2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_predictions_baseline' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         total_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(target)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_edit \u001b[38;5;241m/\u001b[39m total_len \u001b[38;5;28;01mif\u001b[39;00m total_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m cer_baseline \u001b[38;5;241m=\u001b[39m compute_error_rate(\u001b[43mall_predictions_baseline\u001b[49m, all_targets)\n\u001b[1;32m     12\u001b[0m cer_lm \u001b[38;5;241m=\u001b[39m compute_error_rate(all_predictions_lm, all_targets)\n\u001b[1;32m     13\u001b[0m improvement \u001b[38;5;241m=\u001b[39m (cer_baseline \u001b[38;5;241m-\u001b[39m cer_lm) \u001b[38;5;241m/\u001b[39m cer_baseline \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# % improvement\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_predictions_baseline' is not defined"
          ]
        }
      ],
      "source": [
        "# Compute CER/PER\n",
        "def compute_error_rate(predictions, targets):\n",
        "    total_edit = 0\n",
        "    total_len = 0\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        matcher = SequenceMatcher(a=target, b=pred)\n",
        "        total_edit += matcher.distance()\n",
        "        total_len += len(target)\n",
        "    return total_edit / total_len if total_len > 0 else 0.0\n",
        "\n",
        "cer_baseline = compute_error_rate(all_predictions_baseline, all_targets)\n",
        "cer_lm = compute_error_rate(all_predictions_lm, all_targets)\n",
        "improvement = (cer_baseline - cer_lm) / cer_baseline * 100  # % improvement\n",
        "\n",
        "print(f\"\\nBaseline (Greedy):\")\n",
        "print(f\"  CER/PER: {cer_baseline:.4f} ({cer_baseline*100:.2f}%)\")\n",
        "print(f\"\\nWith Language Model:\")\n",
        "print(f\"  CER/PER: {cer_lm:.4f} ({cer_lm*100:.2f}%)\")\n",
        "print(f\"  Improvement: {improvement:.2f}% relative\")\n",
        "print(f\"  Absolute gain: {(cer_baseline - cer_lm)*100:.2f} percentage points\")\n",
        "print(f\"Language Model improved accuracy by {improvement:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "executable": "/usr/bin/env python3",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "ECE_243_Project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
